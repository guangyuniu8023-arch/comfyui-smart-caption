"""
ImageClassifierèŠ‚ç‚¹ - å›¾ç‰‡åˆ†ç±»å™¨
"""
import os
import json
import torch
import numpy as np
from PIL import Image
from ..core import classifier, doubao_client


def load_default_classification_pe():
    """åŠ è½½é»˜è®¤çš„åˆ†ç±»PE"""
    pe_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "prompts", "default_classification.txt")
    try:
        with open(pe_path, 'r', encoding='utf-8') as f:
            return f.read()
    except:
        return "# åˆ†ç±»PEåŠ è½½å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥åˆ†ç±»è§„åˆ™"


def tensor_to_pil_batch(tensor):
    """
    å°†ComfyUIçš„IMAGE tensorè½¬æ¢ä¸ºPIL Imageåˆ—è¡¨
    Args:
        tensor: shape [B, H, W, C], range 0-1
    Returns:
        list of PIL Images
    """
    # è½¬æ¢ä¸ºnumpyï¼ŒèŒƒå›´0-255
    images_np = (255. * tensor.cpu().numpy()).astype(np.uint8)
    
    # è½¬æ¢ä¸ºPIL Imageåˆ—è¡¨
    pil_images = []
    for i in range(images_np.shape[0]):
        img = Image.fromarray(images_np[i])
        pil_images.append(img)
    
    return pil_images


class ImageClassifier:
    """
    å›¾ç‰‡åˆ†ç±»å™¨èŠ‚ç‚¹
    å¯¹è¾“å…¥çš„å›¾ç‰‡è¿›è¡Œåˆ†ç±»ï¼Œè¿”å›åˆ†ç±»æ ‡ç­¾
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # ComfyUIå›¾ç‰‡è¾“å…¥
                "classification_pe": ("STRING", {
                    "multiline": True,
                    "default": load_default_classification_pe(),
                    "dynamicPrompts": False
                }),
                "api_key": ("STRING", {
                    "default": "d26ed5b5-0816-4bec-b045-c353abc16667"
                }),
                "api_url": ("STRING", {
                    "default": "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
                }),
                "model": ("STRING", {
                    "default": "doubao-seed-1-6-250615"
                }),
            },
            "optional": {
                "text_requirement": ("STRING", {
                    "default": "",
                    "multiline": False
                }),
                "mode": (["auto", "single", "multi"], {
                    "default": "auto"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING", "IMAGE")
    RETURN_NAMES = ("classifications", "image")
    FUNCTION = "classify"
    CATEGORY = "SmartCaption"
    
    def classify(self, image, classification_pe, api_key, api_url, model, text_requirement="", mode="auto"):
        """
        åˆ†ç±»ä¸»å‡½æ•°
        
        Returns:
            (classifications_json, image)
        """
        try:
            # è·å–batch size
            batch_size = image.shape[0]
            
            # è½¬æ¢tensorä¸ºPIL Images
            pil_images = tensor_to_pil_batch(image)
            
            # è‡ªåŠ¨åˆ¤æ–­æ¨¡å¼
            if mode == "auto":
                if batch_size == 1:
                    mode = "single"
                else:
                    mode = "multi"
            
            print(f"\n{'='*60}")
            print(f"ğŸ“· ImageClassifier - å¼€å§‹åˆ†ç±»")
            print(f"   æ¨¡å¼: {mode} | å›¾ç‰‡æ•°: {batch_size}")
            print(f"{'='*60}")
            
            # å•å›¾æ¨¡å¼
            if mode == "single" or batch_size == 1:
                result = classifier.classify_single_image(
                    image=pil_images[0],
                    classification_pe=classification_pe,
                    text_requirement=text_requirement,
                    api_key=api_key,
                    api_url=api_url,
                    model=model
                )
                
                classifications_json = json.dumps(result, ensure_ascii=False)
                print(f"âœ… åˆ†ç±»å®Œæˆ: {result.get('style_tag', 'ERROR')}")
                
            # å¤šå›¾æ¨¡å¼
            else:
                result = classifier.classify_multi_images(
                    images=pil_images,
                    classification_pe=classification_pe,
                    text_requirement=text_requirement,
                    api_key=api_key,
                    api_url=api_url,
                    model=model
                )
                
                classifications_json = json.dumps(result, ensure_ascii=False)
                
                if 'style_tag' in result:
                    print(f"âœ… å¤šå›¾æœ‰å…³è”: {result['style_tag']}")
                else:
                    print(f"âš ï¸  å¤šå›¾æ— å…³è”: {result.get('style_tags', [])}")
            
            print(f"{'='*60}\n")
            
            return (classifications_json, image)
        
        except Exception as e:
            error_msg = f"åˆ†ç±»å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            
            # è¿”å›é”™è¯¯ç»“æœ
            error_json = json.dumps({
                "style_tag": "ERROR",
                "error": error_msg
            }, ensure_ascii=False)
            
            return (error_json, image)


# èŠ‚ç‚¹ç±»æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ImageClassifier": ImageClassifier
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageClassifier": "å›¾ç‰‡åˆ†ç±»å™¨ ğŸ“·"
}

